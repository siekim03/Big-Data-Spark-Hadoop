### RDD Transformation
* Create a new RDD from existing one
* "Lazy" becasue the results are only computed when evaluated by actions
* For example, the `map` transformation passes each element of a dataset through a function and returns a new RDD

### RDD Actions
* Actions return a value to driver program after running a computation
* Example, `reduce` action aggregates all the elements of an RDD and returns the result to the driver program

### The Directed Acyclic Graph (DAG)
* A graphical data structure with edges and vertices
* Every new edge is obtained from an older vertex
* In Apahce Spark DAG, the vertices represents RDDs and the edges represent operations such as transformations or actions
* If a node goes down, Spark replicates the DAG and restores the node

### Transformation and Actions
1. Spark creates the DAG when creating an RDD
2. Spark enables the DAG Schedular to perform a transformation and updates the DAG
3. The DAG now points to the new RDD
4. The pointer that transforms RDD is returned to the Spark driver program
5. If there is an action, the driver program that calls the action evaluates the DAG only after Spark completes the action

![](Transformation.PNG?raw=true)
![](Action.PNG?raw=true)

### Datasets
A distributed collection of data that:
* consists of a collection of strongly typed JVM objects
* provides the combined benefits of both RDDs and Spark SQL
* immutable, cannot be deleted or lost
* feature an encoder that converts JVM objects to a tabular representation
* extend DataFrame type-safe and object-oriented API capabilities
* work with both Scala and Java APIs

### Datasets in Spark - Benefits
* Provide compile-time type safety
* Compute faster than RDDs
* Offer the benefits of Spark SQL and DataFrames
* Optimize queries using Catalyst and Tungsten
* Enable improved memory usage and caching
* Use dataset API functions for aggregate operations including sum, average, join and group by

### Datasets & DataFrames compared
|Dataset|DataFrames|
|----------------|---------------|
|Strongly typed|Not typesafe|
|Use unifed Java and Scala APIs|Use APIs in Java, Scala, Python and R|
|Built on top of DataFrames and the latest data abstraction added to Spark|Built on top of RDDs and added in earlier Spark versions|


